 "The following modules are not found yet" error lists builtin modules
 The error can be ignored by entering `N` for the proposed finding of these modules on PyPI, but it shouldn't be thrown at all for builtin modules right?

<pre>(paperpy-dev) <font color="#8AE234"><b>robin@robin-ZenBook-UX533FN</b></font>:<font color="#729FCF"><b>~/paperpy</b></font>$ pigar
<font color="#CC0000">The following modules are not found yet:</font>
  <font color="#C4A000">os</font> referenced from:
    /home/robin/paperpy/setup.py: 2
  <font color="#C4A000">abc</font> referenced from:
    /home/robin/paperpy/build/lib/paperpy/interfaces.py: 5
    /home/robin/paperpy/paperpy/interfaces.py: 5
  <font color="#C4A000">argparse</font> referenced from:
    /home/robin/paperpy/paperpy/cli/__init__.py: 2
<font color="#CC0000">Some of them may be not installed in local environment.</font>
<font color="#CC0000">Try to search PyPI for the missing modules and filter some unnecessary modules? (y/[N]) </font>N
</pre>
Could you provide a minimal environment to reproduce it?

 --yes/--no to answer all possible questions
 
 Add flag for silent execution
 The package is very useful and works better than existing alternatives like pipreqs. However, an option for silent execution (without user interaction) would be very useful. For example, a flag regarding the question about PyPi.
I think that is a good idea, an option like `-y`/`--assumeyes` to answer yes for the question is useful.

Yes, I am also looking for a flag like this. "echo "n" | pigar ...." does not seem to work on linux OS

 [Ubuntu 18 LTS + Anaconda3] Pigar seems to not find all imports in a project.
 I am currently refining a project and need to generate a requirements.txt. For some reason, when I run pigar on the folder containing the main scripts and module src files, it only returns the following:

```
# Automatically generated by https://github.com/damnever/pigar.

# test/cut_encounters.py: 19,20,21,22,23,24,25,29,30
# test/gen_RandEncounters.py: 19,20,21,22,23,24,25,29,30
# test/gen_scatterDB.py: 12,13,14,15,16,17,18,19
# test/get_init-final_database.py: 13,14,15,16,17,18,19,20
# test/sim_cluster.py: 34,35,36,37,38,39,40,43,44,47,48,49,50,51,52
# test/sim_encounters.py: 27,28,29,30,31,32,33,37,38,39
# test/src/tycho/analysis_old.py: 19,20,21,22,23,24,25,28,29,32,33,34,35
# test/src/tycho/create.py: 14,15,16,17,18,19,20,23,24,25
# test/src/tycho/encounter_db.py: 17
# test/src/tycho/multiples3.py: 7,8,9,10,11,12,14,15,16,17,18,19,2077
# test/src/tycho/multiples4.py: 7,8,9,10,11,12,14,15,16,17,18,19,2068
# test/src/tycho/read.py: 18,19,20,21,22,23,24,28,29
# test/src/tycho/stellar_systems.py: 26,27,28,29,30,31,32,35
# test/src/tycho/util.py: 26,27,28,29,30,31,32,34
# test/src/tycho/write.py: 18,19,20,21,22,23,24,27,28
amuse_twobody == 13.1.0

# test/sim_cluster.py: 10
# test/sim_encounters.py: 8,45
# test/src/tycho/analysis_old.py: 42,44,45,46
# test/src/tycho/create.py: 10
# test/src/tycho/read.py: 14
# test/src/tycho/stellar_systems.py: 11,224,225,226,227,235
# test/src/tycho/util.py: 11
# test/src/tycho/write.py: 13
matplotlib == 3.1.3

# test/cut_encounters.py: 7
# test/gen_RandEncounters.py: 7
# test/gen_scatterDB.py: 1
# test/get_init-final_database.py: 1
# test/sim_cluster.py: 9
# test/sim_encounters.py: 7
# test/src/tycho/analysis_old.py: 9
# test/src/tycho/create.py: 9
# test/src/tycho/multiples3.py: 2
# test/src/tycho/multiples4.py: 2
# test/src/tycho/read.py: 13
# test/src/tycho/stellar_systems.py: 10
# test/src/tycho/util.py: 10
# test/src/tycho/write.py: 12,15
numpy == 1.18.1

# test/gen_scatterDB.py: 4,5,6
# test/get_init-final_database.py: 4,6,7
# test/src/tycho/stellar_systems.py: 15,16,17
scipy == 1.4.1
```

This is no-where close to the correct number of imported modules. Am I executing this incorrectly?

~ Joe G.

# test/sim_cluster.py: 10
# test/sim_encounters.py: 8,45
# test/src/tycho/analysis_old.py: 42,44,45,46
# test/src/tycho/create.py: 10
# test/src/tycho/read.py: 14
# test/src/tycho/stellar_systems.py: 11,224,225,226,227,235
# test/src/tycho/util.py: 11
# test/src/tycho/write.py: 13
matplotlib == 3.1.3

# test/cut_encounters.py: 7
# test/gen_RandEncounters.py: 7
# test/gen_scatterDB.py: 1
# test/get_init-final_database.py: 1
# test/sim_cluster.py: 9
# test/sim_encounters.py: 7
# test/src/tycho/analysis_old.py: 9
# test/src/tycho/create.py: 9
# test/src/tycho/multiples3.py: 2
# test/src/tycho/multiples4.py: 2
# test/src/tycho/read.py: 13
# test/src/tycho/stellar_systems.py: 10
# test/src/tycho/util.py: 10
# test/src/tycho/write.py: 12,15
numpy == 1.18.1

# test/gen_scatterDB.py: 4,5,6
# test/get_init-final_database.py: 4,6,7
# test/src/tycho/stellar_systems.py: 15,16,17
scipy == 1.4.1
```

This is no-where close to the correct number of imported modules. Am I executing this incorrectly?

~ Joe G.
I have the same problem, I use pigar on a big torch project, and it doesnt even get close to finding all the imports. torch is not even added, though it says : 

"torch referenced from: blablabla
Some of them may be not installed in local environment.
Try to search PyPI for the missing modules and filter some unnecessary modules? (y/[N]) "

And if I answer yes, it outputs a requirements file without torch and many modules...

I found that the output of pigar varies in function of which virtualenv you run it from. If all the requirements are already installed, it seems that pigar won't output them in the requirements file. Doesn't it defeat the purpose ? The goal is to output all the necessary requirements regardless of whether they are already installed, right ? 

@JPGlaser FYI, I am guessing you are facing the same issue with @jlhervy 

> This is no-where close to the correct number of imported modules

> The goal is to output all the necessary requirements regardless of whether they are already installed, right ?

This is the limitation of pigar, it can not find every package correctly only by the import name, for example:

```Python
import a

def myfunc(whatever):
    print(a.take(whatever))
```

Maybe both `pkg_a` and `pkg_a_fork` offer the same import name `a`, even worse,  they may offer the same function name `take` with different logic internally.


You can read the [FAQ](https://github.com/damnever/pigar#faq), I will add more explanations for that.

Alright, and what about the different output when you use pigar from different virtual environments ? 

For instance, if pigar outputs a requirements.txt with numpy, and you run `pip install numpy`, then re-run pigar, it won't output numpy in the requirements.txt. Is this to be expected ? 

@jlhervy

> and what about the different output when you use pigar from different virtual environments ?

Please read the [FAQ](https://github.com/damnever/pigar#faq), it is the same issue.

> For instance, if pigar outputs a requirements.txt with numpy, and you run pip install numpy, then re-run pigar, it won't output numpy in the requirements.txt. Is this to be expected ?

If this bug is true, please provide a minimal environment to reproduce it.

 V0.10.0 final
 Close #73 
 v0.10.0
 ```
 pip install pigar==0.10.0rc0 
```
 Jupyter notebook(.ipynb) support
 
Hello @damnever! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:







There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: 

##### Comment last updated at 2020-03-14 07:26:00 UTC

 Refactor the main logic
 Fix #47, #58, #61 and #65.

- [x] CI: GitHub workflow
 [WIP] Support ipynb
 This PR adds support for Jupyter notebooks. (closes issue #70)

Could you add some simple test cases?

@damnever I will work on adding this

Since the main code base has been refactored, in order to release a new version soon, I have submitted an another [PR](https://github.com/damnever/pigar/pull/72) which based on your great idea.

Thanks for your contribution again! I am closing this :-D

 Feature request: Detect imports in Jupyter notebooks
 Most of the Jupyter notebooks I download don't come with requirements files, so this would be a common use-case for me.

I looked into how you might do this, and it only takes a few lines. I can work on this.
 tensorflow differences when using conda envoirment
 Hey,

When running pigar on a conda environment, with both tensorflow==1.14.0 and tensorflow_gpu==1.14.0, the requirements.txt created contains tensorflow==1.14.0

Running pigar on the same folder, this time outside the conda environment, creates a requirements.txt with tensorflow_gpu==1.14.0

I assume the second option is the expected behavior since tensorflow_gpu is the one used when running the script.

I'm using Ubuntu-18.04.1 and python 3.7.6

Thanks!
I have added some [FAQ](https://github.com/damnever/pigar#faq), does it help?

 Option to turn off filenames and line numbers in requirements.txt
 This addresses one suggestion from #65 

It adds an option ("-m" or "--minimal") that disables printing of the files and line numbers where each module is printed. By default, the files and line numbers are still printed.
Hello @bganglia! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:







There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: 

##### Comment last updated at 2020-02-08 00:54:15 UTC

@damnever I just figured out why the unit tests are failing. They do not expect parse_args to return an extra item (minimal) at the end of the list. I will modify test_cmd.py to include this.

@damnever I notice there are individual tests for many of the options. Should there be another for this one?

Perhaps I could change the variable "minimal" to "no_comments" or "without_comments". Would that be better?

 Partially fix #48, make parse_reqs read other requirements files recu…
 …rsively when a line has -r.

This pull request addresses, but does not completely solve, #48. It only addresses the -r option, and not --extra-index-url, --trusted-host, etc.

In the modified version of parse_reqs, for every requirements line that looks like "-r more-requirements.txt", the function will open the named file and record its requirements as well.

I tested my code changes using the requirements files in a clone of https://github.com/be-hase/ghe-line-notify/tree/master.

Without this change, I see the following output when I run pigar -c in the root directory of that repository:
```
(envname) username@pcname:~/pigar/examples/ghe-line-notify$ pigar -c
Starting check requirements latest version ...
Searching file in "/home/username/pigar/examples/ghe-line-notify" ...
Checking requirements latest version ...
Traceback (most recent call last):
  File "/home/username/miniconda3/envs/envname/bin/pigar", line 11, in <module>
    load_entry_point('pigar', 'console_scripts', 'pigar')()
  File "/home/username/pigar/pigar/__main__.py", line 271, in main
    Main()
  File "/home/username/pigar/pigar/__main__.py", line 31, in __init__
    self.check_reqs_latest_version(
  File "/home/username/pigar/pigar/__main__.py", line 98, in check_reqs_latest_version
    latest = check_latest_version(pkg)
  File "/home/username/pigar/pigar/pypi.py", line 65, in check_latest_version
    return Downloader().download_package(package).version()
  File "/home/username/pigar/pigar/pypi.py", line 245, in download_package
    pkg_info = self.download(PKG_INFO_URL.format(name))
  File "/home/username/pigar/pigar/pypi.py", line 229, in download
    resp.raise_for_status()
  File "/home/username/miniconda3/envs/envname/lib/python3.8/site-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://pypi.org/pypi/-r%20requirements/common.txt/json/
```

After the change, the program correctly recognizes the additional requirements file and parses the requirements within.
```
(envname) username@pcname:~/pigar/examples/ghe-line-notify$ pigar -c
Starting check requirements latest version ...
Searching file in "/home/username/pigar/examples/ghe-line-notify" ...
Checking requirements latest version ...
Checking requirements latest version done.

 =======================================
  PACKAGE            | CURRENT | LATEST
  -------------------+---------+-------
  alembic            | 0.8.8   | 1.3.2 
  blinker            | 1.4     | 1.4   
  click              | 6.6     | 7.0   
  Flask              | 0.11.1  | 1.1.1 
  Flask-DebugToolbar | 0.10.0  | 0.10.1
  Flask-Migrate      | 2.0.0   | 2.5.2 
  Flask-Script       | 2.0.5   | 2.0.6 
  Flask-SQLAlchemy   | 2.1     | 2.4.1 
  gunicorn           | 19.6.0  | 20.0.4
  itsdangerous       | 0.24    | 1.1.0 
  Jinja2             | 2.8     | 2.10.3
  Mako               | 1.0.4   | 1.1.0 
  MarkupSafe         | 0.23    | 1.1.1 
  python-editor      | 1.0.1   | 1.0.4 
  requests           | 2.11.1  | 2.22.0
  SQLAlchemy         | 1.0.15  | 1.3.12
  Werkzeug           | 0.11.11 | 0.16.0
  psycopg2           | 2.6.2   | 2.8.4 
 =======================================
(envname) username@pcname:~/pigar/examples/ghe-line-notify$ 
```
@damnever When the time comes, it may work to have parse_reqs iterate (filename, reqs) pairs. That would not preserve information about which requirements file references which, though. I am not sure if that makes a difference.

 cannot recognize local module and need clear requirements.txt generation option
 so there are two problem:
1. `pigar` cannot recognize my local module
![image](https://user-images.githubusercontent.com/8676741/71810564-a392be00-30ad-11ea-8c21-bc398fff1a04.png)
![image](https://user-images.githubusercontent.com/8676741/71810579-ab526280-30ad-11ea-849b-8b79a7f217f7.png)

2. `requirements.txt` is too verbose, i believe this feature is from #6 , but it will be great if has a option to control this behavior, such as `--detailed` or something, if i import tons of modules, `requirements.txt` will be pretty huge, the most important thing is git will record the changes if my codes do some changes(that is because `requirements.txt` has those references line numbers), so i need to commit `requirements.txt` frequently
![image](https://user-images.githubusercontent.com/8676741/71810641-c8873100-30ad-11ea-9c98-2d16b50c7a4c.png)


1.
@liesauer I have noticed the first quirk as well.

The code does check whether the imported modules are local files, but if a package with the same name is available on PyPI, it assumes that the user wanted that one. 

See the lines of code below, which execute if you enter "y". (Variables: db = connection to PyPI database, name = package name). If the package is in PyPI, the module is moved from self._maybe_local_mods to in_pypi.

```
                        rows = db.query_all(name)
                        pkgs = [row.package for row in rows]
                        if pkgs:
                            in_pypi.add(name)
                            if name in self._maybe_local_mods:
                                self._maybe_local_mods.remove(name)
                        for pkg in self._best_matchs(name, pkgs):
                            latest = check_latest_version(pkg)
                            reqs.add(pkg, latest, detail.comments)
```

It might be good to assume the user wanted the local module instead, since (at least within the directory) the local module will be imported first anyway. 

On the other hand, downloading the package anyway may be a feature. @damnever, what do you think?

2.
@damnever I can work on adding this option to control the requirements.txt verbosity.

> It might be good to assume the user wanted the local module instead, since (at least within the directory) the local module will be imported first anyway.

i agree with this, but i think implement a import resolver that searches each path of `PYTHONPATH` would be better, if a module insides `lib` or `site-packages`, we can consider that is a built-in module or a `PyPI ` module. and if a local module is found first, then no `PyPI` checking, but this depends on the order in `PYTHONPATH`.


@liesauer, an option to control the reference comments is reasonable. @bganglia I am glad that you can work on this 👍

pigar searches modules remotely only if modules are not installed locally, except in this case, that is why `demjson` and the others are not on the `not found yet` list.



> It might be good to assume the user wanted the local module instead, since (at least within the directory) the local module will be imported first anyway.

I agree with this too.

 Use check path instead of current directory
 This fixes #63

The problem was that the check_reqs_latest_version method of Main did not add check_path to the base name of the requirements file before finding the absolute path, so all of the final paths looked like ``current-directory/file-with-requirements.txt`` instead of ``current-directory/check_path/file-with-requirements.txt``

This pull request adds check_path before finding the absolute path.
@damnever Is this better? I just squashed the whitespace fix into the previous commit

 pigar -c [PATH] uses current directory instead of PATH
 For example, if I want to check the packages of my pigar fork (~/pigar) using
```
cd ~ 
pigar -c pigar/
```
I see the following output:
```
(envname) username@pcname:~$ pigar -c pigar/
Starting check requirements latest version ...
Searching file in "/home/username/pigar" ...
Traceback (most recent call last):
  File "/home/username/miniconda3/envs/envname/bin/pigar", line 11, in <module>
    load_entry_point('pigar', 'console_scripts', 'pigar')()
  File "/home/username/pigar/pigar/__main__.py", line 270, in main
    Main()
  File "/home/username/pigar/pigar/__main__.py", line 32, in __init__
    check_path, ignores, comparison_operator)
  File "/home/username/pigar/pigar/__main__.py", line 86, in check_reqs_latest_version
    reqs.update(parse_reqs(fpath))
  File "/home/username/pigar/pigar/utils.py", line 87, in parse_reqs
    with open(fpath, 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/username/py3_requirements.txt'
```
The file is in ~/pigar, but the code expects it to be in ~, the directory where the command was run.

I can work on this issue.
Good catch!

The current logic seems to be a little buggy, PRs are welcome!

 add conda installation instructions
 Adds the line ``conda install -c conda-forge pigar`` to the instructions
  Thanks!

 pigar command with y (for yes) stopped working
 > Some of them may not install in local environment.
> Try to search PyPI for the missing modules and filter some unnecessary modules? (y/[N]) y
> Checking modules on the PyPI...

```
Traceback (most recent call last):
  File "/mnt/d/ISC/bin/pigar", line 8, in <module>
    sys.exit(main())
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/__main__.py", line 270, in main
    Main()
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/__main__.py", line 37, in __init__
    ignores, comparison_operator)
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/__main__.py", line 108, in generate_reqs
    gr.generate_reqs()
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/__main__.py", line 156, in generate_reqs
    latest = check_latest_version(pkg)
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/pypi.py", line 65, in check_latest_version
    return Downloader().download_package(package).version()
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/pypi.py", line 245, in download_package
    pkg_info = self.download(PKG_INFO_URL.format(name))
  File "/mnt/d/ISC/lib/python3.6/site-packages/pigar/pypi.py", line 229, in download
    resp.raise_for_status()
  File "/mnt/d/ISC/lib/python3.6/site-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://pypi.org/pypi/anoncreds-rc/json/
```
Is this a local package? Could you provide a minimal environment to reproduce it?

 [Bug] pigar doesn't check if the dev dir is part of a bigger git repository.
 In `reqs.py:_search_path`

```
def _search_path(path):
    mapping = dict()

    for file in os.listdir(path):
        # Install from PYPI.
        if fnmatch.fnmatch(file, '*-info'):
            ...

        # Install from local and available in GitHub.
        elif fnmatch.fnmatch(file, '*-link'):
            ...

            # Check .git dir.
            git_path = os.path.join(dev_dir, '.git')
            ...
            
    return mapping
```

The git directory checking is sufficient for the best case scenario where the package's code is next to the `.git` directory. However if your package is part of a bigger git repository, the checking fails because `git_path` doesn't exist.

One of the potential way of solving this issue would be to write a similar logic to what `pip` does, a subprocess call to `git rev-parse --git-dir`. See: [this line](https://github.com/pypa/pip/blob/master/src/pip/_internal/vcs/git.py#L319). 

If adding `pip` to the dependencies is not an issue, using `pip._internal.vcs.git.Git` directly for the full git logic could be another option.

Thanks for reporting this!

You are welcome to submit a PR to address the issue.

 pigar installed with Python 3.7 seemingly does not work
 On my Mac (10.11.6) with Python 3.7, after successfully installing pigar with
`python -m pip install pigar`,
I see that I can import it within python, but the `pigar ___` command does not do anything for me in the terminal.

Whereas, if I install pigar to work with Python 2.7, using
`pip install pigar`,
the `pigar ___` command does work, but it does not pick up any Python 3 libraries.

How could I make pigar work through the mac's terminal, *and* recognize Python 3 packages?
Having returned to an old project that needed a big `requirements.txt`, I revisited this topic, and got `pigar` to work by using the manual installation instructions on the front page.

 Pigar not looking into all files of package despite having __init__.py
 In [this](https://github.com/socialbotspy/LinkedinPy) repo in the `requirements.txt` generated at root of repo by `pigar`, you can see it totally ignores all dependencies in `linkedinpy/linkedinpy.py`. Same for a few other files as well.
You can clearly see `linkedinpy` is a package and it has `__init__.py`
I am using `pigar` version = `0.9.2`
 PyPI 404
 Traceback (most recent call last):
  File "/usr/local/bin/pigar", line 11, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.6/site-packages/pigar/__main__.py", line 270, in main
    Main()
  File "/usr/local/lib/python3.6/site-packages/pigar/__main__.py", line 37, in __init__
    ignores, comparison_operator)
  File "/usr/local/lib/python3.6/site-packages/pigar/__main__.py", line 108, in generate_reqs
    gr.generate_reqs()
  File "/usr/local/lib/python3.6/site-packages/pigar/__main__.py", line 156, in generate_reqs
    latest = check_latest_version(pkg)
  File "/usr/local/lib/python3.6/site-packages/pigar/pypi.py", line 65, in check_latest_version
    return Downloader().download_package(package).version()
  File "/usr/local/lib/python3.6/site-packages/pigar/pypi.py", line 245, in download_package
    pkg_info = self.download(PKG_INFO_URL.format(name))
  File "/usr/local/lib/python3.6/site-packages/pigar/pypi.py", line 229, in download
    resp.raise_for_status()
  File "/usr/local/lib/python3.6/site-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://pypi.org/pypi/ftl-base/json/


Perhaps there was a change in the url?
What did you do? Could you provide more information, such as environment, etc.

There is no project named `ftl-base`: https://pypi.org/search/?q=ftl-base

I entered `y` on "Try to search PyPI for the missing modules and filter some unnecessary modules?"
`N` option generated the file.

I think I misread the error as pigar failing. I was expecting it would not throw an error and exit the program. I will close it.

 pigar --update processing stops
 Starting update database ...
The process will take a long time!!!
Traceback (most recent call last):
  File "d:\python36\lib\runpy.py", line 193, in _run_module_as_main
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "d:\python36\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "d:\python36\lib\multiprocessing\spawn.py", line 115, in _main
    self = reduction.pickle.load(from_parent)
EOFError: Ran out of input
    "__main__", mod_spec)
  File "d:\python36\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "D:\Python36\Scripts\pigar.exe\__main__.py", line 9, in <module>
  File "d:\python36\lib\site-packages\pigar\__main__.py", line 261, in main
    Main()
  File "d:\python36\lib\site-packages\pigar\__main__.py", line 29, in __init__
    self.update_db()
  File "d:\python36\lib\site-packages\pigar\__main__.py", line 46, in update_db
    update_db()
  File "d:\python36\lib\site-packages\pigar\pypi.py", line 81, in update_db
    updater.run()
  File "d:\python36\lib\site-packages\pigar\pypi.py", line 138, in run
    proc.start()
  File "d:\python36\lib\multiprocessing\process.py", line 105, in start
    self._popen = self._Popen(self)
  File "d:\python36\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "d:\python36\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "d:\python36\lib\multiprocessing\popen_spawn_win32.py", line 65, in __init__
    reduction.dump(process_obj, to_child)
  File "d:\python36\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
TypeError: can't pickle _thread.lock objects

I am using pigar 0.9.0
 Bump version: 0.9.2
 
 Support comparison operators
 Dirty code..
Hello @damnever! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:







There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: 

##### Comment last updated at 2019-04-11 11:07:17 UTC

 Add support for Notebooks
 Please add support for Ipython Notebooks. A lot of data science/machine learning repos are written partially in python files and partially in notebooks. It would be nice to have a flag that could enable the inclusion of notebooks.
Did you mean handling .ipynb as python scripts?

exactly

I do not think it is a good idea.

Maybe [`this`](https://www.google.com/search?newwindow=1&q=install+python+package+within+ipython+notebook) will meet you need. Using containers like docker would be a good idea too.



maybe  there is a miscommunication or maybe not, but to clarify. I think it would be nice if you could add a flag for .ipynb.
`pegar --include_notebooks=True`
this would mean that pegar would add the imports from notebook files to the requirements.txt that it generates as if they were normal .py files. 

If you think it's a bad idea, that's fine, i just wanted to clarify encase i miscommunicated.

I think this kind of job could be done by a pigar plugin or something similar. For now, I want to keep pigar as simple as possible, since I rarely use pigar. Even though, contributions are welcome!

Anyway, Jupyter notebook(`.ipynb`) has been [supported](https://pypi.org/project/pigar/). 😅 

 PYPI_URL is hardcoded, does not pick up custom pip configuration.
 The following piece of code can be improved. `PYPI_URL 
Pigar can check whether there is a custom pypi configuration exists or not.  If there is not custom url, it can get by default https://pypi.org.


The other PyPI mirrors may has different page structures, I don't know if pigar can handle it gracefully.

 Upgrade requests to fix potential security vulnerabilities
 
 Pigar requiring user permission
 I'm trying to use pigar in a personal project, but i'm getting this strange error and I don't now why, can someone help me with that?

environement:
virtualenvwrapper==latest
os ubuntu=latest
pigar 0.9.0

`Traceback (most recent call last):
  File "/home/adailtonnascimento/.local/bin/pigar", line 11, in <module>
    sys.exit(main())
  File "/home/adailtonnascimento/.local/lib/python2.7/site-packages/pigar/__main__.py", line 261, in main
    Main()
  File "/home/adailtonnascimento/.local/lib/python2.7/site-packages/pigar/__main__.py", line 35, in __init__
    self.generate_reqs(save_path, project_path, ignores)
  File "/home/adailtonnascimento/.local/lib/python2.7/site-packages/pigar/__main__.py", line 101, in generate_reqs
    gr = GenerateReqs(save_path, check_path, ignores, self.installed_pkgs)
  File "/home/adailtonnascimento/.local/lib/python2.7/site-packages/pigar/__main__.py", line 41, in installed_pkgs
    self._installed_pkgs = get_installed_pkgs_detail()
  File "/home/adailtonnascimento/.local/lib/python2.7/site-packages/pigar/reqs.py", line 300, in get_installed_pkgs_detail
    mapping.update(_search_path(path))
  File "/home/adailtonnascimento/.local/lib/python2.7/site-packages/pigar/reqs.py", line 339, in _search_path
    info_dir = [_file for _file in os.listdir(dev_dir)
OSError: [Errno 13] Permission denied: '/root/src/polls'`
I forgot to start my virtualenvenv sorry.

 Relaxing version constraints
 Appears that `pigar` now has [very tight version constraints on its dependencies]( https://github.com/damnever/pigar/blob/233658e3468c297bb11889d5a71524bc2a086071/setup.py#L27-L28 ). Would it be possible to relax these (i.e. make them lower bounds instead)?
Seconding this and hoping for a patch, it's introducing version management issues when libraries require newer versions of `requests`

